{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parallel Programming with Python\n",
    "\n",
    "Python has the ability to run in parallel, using both shared memory and distributed memory methods.  This tutorial is meant to give you a brief introduction to what's available and, more importantly, when it's appropriate to use."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python Threading\n",
    "\n",
    "Generally, Python threading is terrible.  But it shouldn't be:\n",
    "\n",
    "* POSIX threads\n",
    "* Shared memory with parent process\n",
    "* Lightweight threads"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Global Interpreter Lock (GIL)\n",
    "\n",
    "In order to keep memory coherent, the Python intrepter only allows a single thread to run at once....killing performance for any kind of shared memory workload.\n",
    "\n",
    "There are (some) good reasons for this (I/O, intrepreter maintenance, etc.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example: Calculate Pi with Python Threads"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simple process:\n",
    "* Inscribe a circle in a square\n",
    "* Throw darts at it\n",
    "* Count how many are inside the circle and how many are outside\n",
    "* Use the ratio of those to compute pi\n",
    "\n",
    "<img src=\"../img/circle_and_square.png\" style=\"height:350px\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.139148\n"
     ]
    }
   ],
   "source": [
    "from threading import Thread, Lock\n",
    "import random\n",
    "\n",
    "lock = Lock() # lock for making operations atomic\n",
    "\n",
    "def calcInside(nsamples,rank):\n",
    "    global inside # we need something everyone can share random.seed(rank)\n",
    "    random.seed(rank)\n",
    "    for i in range(nsamples):\n",
    "        x = random.random()\n",
    "        y = random.random()\n",
    "        if (x*x)+(y*y)<1:\n",
    "            lock.acquire() # GIL doesn't always save you\n",
    "            inside += 1\n",
    "            lock.release()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    nt=4 # thread count\n",
    "    inside = 0 # initialise\n",
    "    samples=int(10e5/nt)\n",
    "    threads=[Thread(target=calcInside, args=(samples,i)) for i in range(nt)]\n",
    "    \n",
    "    for t in threads: t.start()\n",
    "    for t in threads: t.join()\n",
    "    \n",
    "    print((4.0*inside)/(1.0*samples*nt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A few notes on the above code:\n",
    "\n",
    "* Python data-structures (e.g. lists, dictionaries, etc.) are thread-safe, meaning that when updating their values the GIL is held and other threads wait until it's released before updating object  \n",
    "<br>\n",
    "* Simpler data structures like integegers aren't thread-safe, which means we could have mulitple threads accessing the same object and either data could be corrupted or missed  \n",
    "<br>\n",
    "* We have to explicitly lock our `inside` counter in the above code to avoid this"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subprocess\n",
    "\n",
    "Python's `subprocess` module allows the Python intrepter to spawn and control processes that aren't affected by the GIL.  The basic command in the `subprocess` module is `Popen()`, which lets you open a proces:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "pi=subprocess.Popen('python -c \"import math; print(math.pi)\"',shell=True,stdout=subprocess.PIPE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'3.141592653589793\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pi.stdout.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pi.pid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some issues with subprocess:\n",
    "* Shared memory is tricky at best\n",
    "* Locks and atomics are difficult\n",
    "\n",
    "It's really designed for launching independent processes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmds = [\n",
    "    'echo foo',\n",
    "    'echo bar',\n",
    "    'date',\n",
    "    'hostname'\n",
    "]\n",
    "\n",
    "tasks = [subprocess.Popen(c, shell=True) for c in cmds]\n",
    "for t in tasks: t.wait()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at another method..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiprocessing\n",
    "\n",
    "This module blends together Python threads and subprocesses.  It bypasses the GIL, so threads can be used and see some performance.  Under the hood it uses subprocesses, but has a manager to handle things like synchronization and distribuited sharing (but still not true shared memory)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating pi with Multiprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the `Pool` module to calculate pi.  `Pool` allows you to define a group of worker processes that you will then divide some work amongst.  `Pool` takes two inputs:\n",
    "\n",
    "* A function that we want to run across the pool of workers\n",
    "* An iterable...some way to identify how we're splitting up work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.14226\n"
     ]
    }
   ],
   "source": [
    "import multiprocessing as mp\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "processes = mp.cpu_count()\n",
    "nsamples = int(10e5/processes)\n",
    "\n",
    "def calcInside(rank):\n",
    "    inside = 0\n",
    "    random.seed(rank)\n",
    "    for i in range(nsamples):\n",
    "        x = random.random();\n",
    "        y = random.random();\n",
    "        if (x*x)+(y*y)<1:\n",
    "            inside += 1\n",
    "    return (4.0*inside)/nsamples\n",
    "\n",
    "# Important to check if main so child processes don't try to run it\n",
    "if __name__ == '__main__':\n",
    "    pool = mp.Pool(processes)\n",
    "    result = pool.map(calcInside, range(processes))\n",
    "    print(np.mean(result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `Multiprocessing` module has support for other parallel constructs like process communication and locks.  We won't go into them today, but you should be aware of them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While Multiprocessing is certainly an improvement over `subprocess` and Python threads, it does come with overhead that impacts performance.  Additionally, it will only scale to a single node (no distributed memory capability).\n",
    "\n",
    "In order to do that, we need..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## mpi4py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`mpi4py` is a set of bindings to make use of MPI, Message Passing Interface.  MPI forms the basis of most applications that run on HPC systems today.  We won't cover MPI today, but it is important to understand a few basics to understand what `mpi4py` is doing.\n",
    "\n",
    "Simply, all MPI allows is for processors to communicate data between each other.   Each process executes the same instructions (or code), but on different parts of the data.  At points throughout the computation, they may need to send or receive data to/from memory locations that are non-local.  MPI is the API that allows for this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hello World"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "from mpi4py import MPI\n",
    "import sys\n",
    "\n",
    "size = MPI.COMM_WORLD.Get_size()\n",
    "rank = MPI.COMM_WORLD.Get_rank()\n",
    "name = MPI.Get_processor_name()\n",
    "\n",
    "sys.stdout.write(\n",
    "    \"Hello, World! I am process %d of %d on %s.\\n\"\n",
    "    % (rank, size, name))\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello, World! I am process 2 of 4 on 8819eff33fb3.\r\n",
      "Hello, World! I am process 3 of 4 on 8819eff33fb3.\r\n",
      "Hello, World! I am process 0 of 4 on 8819eff33fb3.\r\n",
      "Hello, World! I am process 1 of 4 on 8819eff33fb3.\r\n"
     ]
    }
   ],
   "source": [
    "!mpirun -np 4 python ../code/mpi4py/helloworld.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Point-to-Point Communication"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "from mpi4py import MPI\n",
    "\n",
    "comm = MPI.COMM_WORLD\n",
    "rank = comm.Get_rank()\n",
    "\n",
    "if rank == 0:\n",
    "    data = {'a': 7, 'b': 3.14}\n",
    "    comm.send(data, dest=1)\n",
    "elif rank == 1:\n",
    "    data = comm.recv(source=0)\n",
    "    print('On process 1, data is ',data)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On process 1, data is  {'a': 7, 'b': 3.14}\r\n"
     ]
    }
   ],
   "source": [
    "!mpirun -np 4 python ../code/mpi4py/pt2pt.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We sent a dictionary, but we can also send NumPy arrays (and we should try to do that all the time):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "from mpi4py import MPI\n",
    "import numpy as np\n",
    "\n",
    "comm = MPI.COMM_WORLD\n",
    "rank = comm.Get_rank()\n",
    "\n",
    "if rank == 0:\n",
    "    # in real code, this section might\n",
    "    # read in data parameters from a file\n",
    "    numData = 10  \n",
    "    comm.send(numData, dest=1)\n",
    "\n",
    "    data = np.linspace(0.0,3.14,numData)  \n",
    "    comm.Send(data, dest=1)\n",
    "\n",
    "elif rank == 1:\n",
    "\n",
    "    numData = comm.recv(source=0)\n",
    "    print('Number of data to receive: ',numData)\n",
    "\n",
    "    data = np.empty(numData, dtype='d')  # allocate space to receive the array\n",
    "    comm.Recv(data, source=0)\n",
    "\n",
    "    print('data received: ',data)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of data to receive:  10\r\n",
      "data received:  [0.         0.34888889 0.69777778 1.04666667 1.39555556 1.74444444\r\n",
      " 2.09333333 2.44222222 2.79111111 3.14      ]\r\n"
     ]
    }
   ],
   "source": [
    "!mpirun -np 4 python ../code/mpi4py/pt2pt_numpy.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collectives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Collectives are operations that all processors execute together.  They may execute at slightly different times, but they all will call the same function.  These are useful for operations like gathering data onto a root process, or distributing data from one to all.\n",
    "\n",
    "Hers' an example of performing a `gather` operation:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../img/gather.png\" style=\"height:150px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "from mpi4py import MPI\n",
    "import numpy as np\n",
    "\n",
    "comm = MPI.COMM_WORLD\n",
    "size = comm.Get_size()\n",
    "rank = comm.Get_rank()   \n",
    "\n",
    "numDataPerRank = 10  \n",
    "sendbuf = np.linspace(rank*numDataPerRank+1,(rank+1)*numDataPerRank,numDataPerRank)\n",
    "print('Rank: ',rank, ', sendbuf: ',sendbuf)\n",
    "\n",
    "recvbuf = None\n",
    "if rank == 0:\n",
    "    recvbuf = np.empty(numDataPerRank*size, dtype='d')  \n",
    "\n",
    "comm.Gather(sendbuf, recvbuf, root=0)\n",
    "\n",
    "if rank == 0:\n",
    "    print('Rank: ',rank, ', recvbuf received: ',recvbuf)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rank:  3 , sendbuf:  [31. 32. 33. 34. 35. 36. 37. 38. 39. 40.]\n",
      "Rank:  1 , sendbuf:  [11. 12. 13. 14. 15. 16. 17. 18. 19. 20.]\n",
      "Rank:  2 , sendbuf:  [21. 22. 23. 24. 25. 26. 27. 28. 29. 30.]\n",
      "Rank:  0 , sendbuf:  [ 1.  2.  3.  4.  5.  6.  7.  8.  9. 10.]\n",
      "Rank:  0 , recvbuf received:  [ 1.  2.  3.  4.  5.  6.  7.  8.  9. 10. 11. 12. 13. 14. 15. 16. 17. 18.\n",
      " 19. 20. 21. 22. 23. 24. 25. 26. 27. 28. 29. 30. 31. 32. 33. 34. 35. 36.\n",
      " 37. 38. 39. 40.]\n"
     ]
    }
   ],
   "source": [
    "!mpirun -np 4 python ../code/mpi4py/gather.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "mpi4py has the ability to ship *any* serialisable Python object.  That means that objects like `dicts` need to be converted to a byte stream, a process called pickling.  That means a Python object (except for strings and ints) needs to be pickled, sent over MPI, and then repickled...adding significant overhead."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, arrays in NumPy map to C memory allocations, and mpi4py can send them at *almost* the speed of C/C++/Fortran:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../img/allgather_bench.png\" style=\"height:450px\">\n",
    "<img src=\"../img/latency_bench.png\" style=\"height:450px\">\n",
    "<img src=\"../img/bandwidth_bench.png\" style=\"height:450px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computing Pi\n",
    "\n",
    "Now let's look at how we can comput pi with mpi4py."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ../code/mpi4py/pi_mpi.py\n"
     ]
    }
   ],
   "source": [
    "from mpi4py import MPI\n",
    "import numpy\n",
    "\n",
    "# Function to calcualte pi that each MPI rank will use\n",
    "def compute_pi(samples):\n",
    "    count = 0\n",
    "    for x, y in samples:\n",
    "        if x**2 + y**2 <= 1:\n",
    "            count += 1\n",
    "    pi = 4*float(count)/len(samples)\n",
    "    return pi\n",
    "\n",
    "# Set up our MPI environment\n",
    "comm = MPI.COMM_WORLD\n",
    "nprocs = comm.Get_size()\n",
    "myrank = comm.Get_rank()\n",
    "\n",
    "# Processor 0 generates random samples that each processor will use\n",
    "if myrank == 0:\n",
    "    N = 100000 // nprocs\n",
    "    samples = numpy.random.random((nprocs, N, 2))\n",
    "else:\n",
    "    samples = None\n",
    "\n",
    "# Distribute the samples amongst all processors wiht MPI_Scatter\n",
    "samples = comm.scatter(samples, root=0)\n",
    "\n",
    "# Each processors calculates their value of pi (we'll take the average)\n",
    "mypi = compute_pi(samples) / nprocs\n",
    "\n",
    "# MPI_Reduce collects all individual \n",
    "pi = comm.reduce(mypi, op=MPI.SUM, root=0)\n",
    "\n",
    "if myrank == 0:\n",
    "    error = abs(pi - numpy.pi)\n",
    "    print(\"pi is approximately %.16f, error is %.16f\" % (pi, error))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That runs on a single MPI process, so let's launch it in parallel:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pi is approximately 3.1454400000000002, error is 0.0038473464102071\r\n"
     ]
    }
   ],
   "source": [
    "!mpirun -np 4 ../code/mpi4py/pi_mpi.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ipyparallel\n",
    "\n",
    "ipyparallel is Python package for creating and running clusters in Jupyter (used to be known as IPython.parallel).  It offers a nice, interactive method for developing and running parallel Python applications.\n",
    "\n",
    "I'd still recommend using a more traditional approach of a standalone Python script and batch script submitted to a scheduler for large-scale production runs, but for rapid development and prototyping, ipyparalell is a valuable tool.\n",
    "\n",
    "There a 4 parts to the ipyparallel architecture:\n",
    "* Engine\n",
    "* Hub\n",
    "* Client\n",
    "* Schedulers\n",
    "\n",
    "<img src=\"../img/ipyparallel_overview.png\" style=\"float: center;\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 3]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import ipyparallel as ipp\n",
    "c = ipp.Client()\n",
    "c.ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pi is approximately 3.1425336000000001, error is 0.0009409464102070\n"
     ]
    }
   ],
   "source": [
    "run ../code/mpi4py/pi_mpi.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Real Example\n",
    "\n",
    "For those that don't consider Python a vialble HPC language, here's an example of what you can do with Python at scale:\n",
    "\n",
    "<img src=\"../img/pyfr_logo.png\" style=\"height:250px\">\n",
    "\n",
    "\n",
    "[PyFR](http://www.pyfr.org/index.php) - A Python framework for solving advection-diffucions problems.\n",
    "\n",
    "Features:\n",
    "* **Multi-platform**\n",
    "    * AMD GPUs\n",
    "    * NVIDIA GPUs\n",
    "    * CPUs\n",
    "    * Intel MIC\n",
    "    * Even Raspberyy Pi  \n",
    "<br>\n",
    "* **Parallelism**\n",
    "    * MPI (mpi4py)\n",
    "    * CUDA (PyCUDA)\n",
    "    * OpenMP (pyMIC for KNL)\n",
    "    * OpenCL (PyOpenCL)\n",
    "    * HDF5 Parallel I/O (h5py)  \n",
    "<br>    \n",
    "* **Scalable**\n",
    "    * 18,000 K20X GPUs on Titan (ORNL)\n",
    "    * 195 billion DOFs\n",
    "    * 58% peak performance (Summit HPL benchmark was 71%)\n",
    "    * SC16 Best Paper/Gordon Bell nominee\n",
    "    \n",
    "And it does all that in about **8000 lines of code**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../img/pyfr-sim.gif\" style=\"height:250px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Euler Demo (from PyFR website)\n",
    "\n",
    "Here we'll run a small PyFR demo, a 2D Euler vortex simulation.  We have a separate Conda environment in our notebook for PyFR (select the pyfr kernel from the Kernel menu:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../img/conda-nb.png\" style=\"height:600px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE:** For this small example, runnning in parallel inside our notebook give pretty terrible performance.  I've written the commands "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pyfr import ../code/pyfr/euler_vortex_2d.msh ../code/pyfr/euler_vortex_2d.pyfrm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to partition the mesh depending on how many processors we want to use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/pyfr/lib/python3.7/site-packages/h5py/_hl/dataset.py:313: H5pyDeprecationWarning: dataset.value has been deprecated. Use dataset[()] instead.\r\n",
      "  \"Use dataset[()] instead.\", H5pyDeprecationWarning)\r\n"
     ]
    }
   ],
   "source": [
    "!pyfr partition 4 ../code/pyfr/euler_vortex_2d.pyfrm ../code/pyfr/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/pyfr/lib/python3.7/site-packages/h5py/_hl/dataset.py:313: H5pyDeprecationWarning: dataset.value has been deprecated. Use dataset[()] instead.\n",
      "  \"Use dataset[()] instead.\", H5pyDeprecationWarning)\n",
      "/opt/conda/envs/pyfr/lib/python3.7/site-packages/pyfr-1.8.0-py3.7.egg/pyfr/shapes.py:274: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K\u001b[G   0.2% [>                           ] 0.21/100.00 ela: 00:00:00 rem: 00:00:47\u001b[2K\u001b[G   0.7% [>                           ] 0.70/100.00 ela: 00:00:00 rem: 00:00:28\u001b[2K\u001b[G   1.1% [>                           ] 1.05/100.00 ela: 00:00:00 rem: 00:00:28\u001b[2K\u001b[G   1.5% [>                           ] 1.55/100.00 ela: 00:00:00 rem: 00:00:25\u001b[2K\u001b[G   2.1% [=>                          ] 2.06/100.00 ela: 00:00:00 rem: 00:00:23\u001b[2K\u001b[G   2.6% [=>                          ] 2.57/100.00 ela: 00:00:00 rem: 00:00:22\u001b[2K\u001b[G   3.0% [=>                          ] 3.02/100.00 ela: 00:00:00 rem: 00:00:22\u001b[2K\u001b[G   3.5% [=>                          ] 3.50/100.00 ela: 00:00:00 rem: 00:00:22\u001b[2K\u001b[G   4.0% [=>                          ] 4.00/100.00 ela: 00:00:00 rem: 00:00:21\u001b[2K\u001b[G   4.5% [=>                          ] 4.53/100.00 ela: 00:00:01 rem: 00:00:21\u001b[2K\u001b[G   5.1% [=>                          ] 5.05/100.00 ela: 00:00:01 rem: 00:00:20\u001b[2K\u001b[G   5.6% [==>                         ] 5.57/100.00 ela: 00:00:01 rem: 00:00:20\u001b[2K\u001b[G   6.1% [==>                         ] 6.07/100.00 ela: 00:00:01 rem: 00:00:20\u001b[2K\u001b[G   6.6% [==>                         ] 6.59/100.00 ela: 00:00:01 rem: 00:00:19\u001b[2K\u001b[G   7.1% [==>                         ] 7.07/100.00 ela: 00:00:01 rem: 00:00:19\u001b[2K\u001b[G   7.6% [==>                         ] 7.59/100.00 ela: 00:00:01 rem: 00:00:19\u001b[2K\u001b[G   8.1% [==>                         ] 8.10/100.00 ela: 00:00:01 rem: 00:00:19\u001b[2K\u001b[G   8.6% [==>                         ] 8.59/100.00 ela: 00:00:01 rem: 00:00:19\u001b[2K\u001b[G   9.1% [==>                         ] 9.07/100.00 ela: 00:00:01 rem: 00:00:19\u001b[2K\u001b[G   9.6% [===>                        ] 9.59/100.00 ela: 00:00:02 rem: 00:00:18\u001b[2K\u001b[G  10.0% [===>                        ] 10.00/100.00 ela: 00:00:02 rem: 00:00:19\u001b[2K\u001b[G  10.4% [===>                        ] 10.40/100.00 ela: 00:00:02 rem: 00:00:19\u001b[2K\u001b[G  10.7% [===>                        ] 10.69/100.00 ela: 00:00:02 rem: 00:00:19\u001b[2K\u001b[G  11.1% [===>                        ] 11.09/100.00 ela: 00:00:02 rem: 00:00:19\u001b[2K\u001b[G  11.6% [===>                        ] 11.57/100.00 ela: 00:00:02 rem: 00:00:19\u001b[2K\u001b[G  12.1% [===>                        ] 12.08/100.00 ela: 00:00:02 rem: 00:00:19\u001b[2K\u001b[G  12.3% [===>                        ] 12.30/100.00 ela: 00:00:02 rem: 00:00:19\u001b[2K\u001b[G  12.8% [===>                        ] 12.78/100.00 ela: 00:00:02 rem: 00:00:19\u001b[2K\u001b[G  13.3% [====>                       ] 13.27/100.00 ela: 00:00:02 rem: 00:00:19\u001b[2K\u001b[G  13.8% [====>                       ] 13.78/100.00 ela: 00:00:03 rem: 00:00:18\u001b[2K\u001b[G  14.3% [====>                       ] 14.25/100.00 ela: 00:00:03 rem: 00:00:18\u001b[2K\u001b[G  14.7% [====>                       ] 14.74/100.00 ela: 00:00:03 rem: 00:00:18\u001b[2K\u001b[G  15.2% [====>                       ] 15.17/100.00 ela: 00:00:03 rem: 00:00:18\u001b[2K\u001b[G  15.7% [====>                       ] 15.68/100.00 ela: 00:00:03 rem: 00:00:18\u001b[2K\u001b[G  16.2% [====>                       ] 16.16/100.00 ela: 00:00:03 rem: 00:00:18\u001b[2K\u001b[G  16.7% [====>                       ] 16.66/100.00 ela: 00:00:03 rem: 00:00:18\u001b[2K\u001b[G  17.0% [=====>                      ] 17.05/100.00 ela: 00:00:03 rem: 00:00:18\u001b[2K\u001b[G  17.5% [=====>                      ] 17.53/100.00 ela: 00:00:03 rem: 00:00:17\u001b[2K\u001b[G  18.0% [=====>                      ] 18.01/100.00 ela: 00:00:03 rem: 00:00:17\u001b[2K\u001b[G  18.5% [=====>                      ] 18.51/100.00 ela: 00:00:04 rem: 00:00:17\u001b[2K\u001b[G  18.9% [=====>                      ] 18.86/100.00 ela: 00:00:04 rem: 00:00:17\u001b[2K\u001b[G  19.3% [=====>                      ] 19.26/100.00 ela: 00:00:04 rem: 00:00:17\u001b[2K\u001b[G  19.6% [=====>                      ] 19.64/100.00 ela: 00:00:04 rem: 00:00:17\u001b[2K\u001b[G  20.0% [=====>                      ] 20.00/100.00 ela: 00:00:04 rem: 00:00:17\u001b[2K\u001b[G  20.3% [=====>                      ] 20.32/100.00 ela: 00:00:04 rem: 00:00:17\u001b[2K\u001b[G  20.8% [======>                     ] 20.79/100.00 ela: 00:00:04 rem: 00:00:17\u001b[2K\u001b[G  21.2% [======>                     ] 21.18/100.00 ela: 00:00:04 rem: 00:00:17\u001b[2K\u001b[G  21.7% [======>                     ] 21.66/100.00 ela: 00:00:04 rem: 00:00:17\u001b[2K\u001b[G  22.0% [======>                     ] 21.97/100.00 ela: 00:00:04 rem: 00:00:17\u001b[2K\u001b[G  22.3% [======>                     ] 22.32/100.00 ela: 00:00:05 rem: 00:00:17\u001b[2K\u001b[G  22.7% [======>                     ] 22.74/100.00 ela: 00:00:05 rem: 00:00:17\u001b[2K\u001b[G  23.2% [======>                     ] 23.19/100.00 ela: 00:00:05 rem: 00:00:17\u001b[2K\u001b[G  23.7% [======>                     ] 23.68/100.00 ela: 00:00:05 rem: 00:00:17\u001b[2K\u001b[G  24.2% [=======>                    ] 24.18/100.00 ela: 00:00:05 rem: 00:00:17\u001b[2K\u001b[G  24.7% [=======>                    ] 24.66/100.00 ela: 00:00:05 rem: 00:00:16\u001b[2K\u001b[G  25.2% [=======>                    ] 25.15/100.00 ela: 00:00:05 rem: 00:00:16\u001b[2K\u001b[G  25.6% [=======>                    ] 25.64/100.00 ela: 00:00:05 rem: 00:00:16\u001b[2K\u001b[G  26.0% [=======>                    ] 26.05/100.00 ela: 00:00:05 rem: 00:00:16\u001b[2K\u001b[G  26.5% [=======>                    ] 26.46/100.00 ela: 00:00:05 rem: 00:00:16\u001b[2K\u001b[G  26.9% [=======>                    ] 26.94/100.00 ela: 00:00:06 rem: 00:00:16\u001b[2K\u001b[G  27.4% [=======>                    ] 27.44/100.00 ela: 00:00:06 rem: 00:00:16\u001b[2K\u001b[G  27.9% [========>                   ] 27.94/100.00 ela: 00:00:06 rem: 00:00:16\u001b[2K\u001b[G  28.4% [========>                   ] 28.42/100.00 ela: 00:00:06 rem: 00:00:15\u001b[2K\u001b[G  28.8% [========>                   ] 28.80/100.00 ela: 00:00:06 rem: 00:00:15\u001b[2K\u001b[G  29.1% [========>                   ] 29.08/100.00 ela: 00:00:06 rem: 00:00:15\u001b[2K\u001b[G  29.4% [========>                   ] 29.43/100.00 ela: 00:00:06 rem: 00:00:15\u001b[2K\u001b[G  29.9% [========>                   ] 29.85/100.00 ela: 00:00:06 rem: 00:00:15\u001b[2K\u001b[G  30.2% [========>                   ] 30.25/100.00 ela: 00:00:06 rem: 00:00:15\u001b[2K\u001b[G  30.7% [========>                   ] 30.73/100.00 ela: 00:00:06 rem: 00:00:15\u001b[2K\u001b[G  31.2% [========>                   ] 31.23/100.00 ela: 00:00:07 rem: 00:00:15\u001b[2K\u001b[G  31.7% [=========>                  ] 31.75/100.00 ela: 00:00:07 rem: 00:00:15\u001b[2K\u001b[G  32.2% [=========>                  ] 32.20/100.00 ela: 00:00:07 rem: 00:00:15\u001b[2K\u001b[G  32.7% [=========>                  ] 32.65/100.00 ela: 00:00:07 rem: 00:00:15\u001b[2K\u001b[G  33.0% [=========>                  ] 33.00/100.00 ela: 00:00:07 rem: 00:00:15\u001b[2K\u001b[G  33.3% [=========>                  ] 33.34/100.00 ela: 00:00:07 rem: 00:00:15\u001b[2K\u001b[G  33.7% [=========>                  ] 33.75/100.00 ela: 00:00:07 rem: 00:00:15\u001b[2K\u001b[G  34.2% [=========>                  ] 34.21/100.00 ela: 00:00:07 rem: 00:00:14\u001b[2K\u001b[G  34.6% [=========>                  ] 34.64/100.00 ela: 00:00:07 rem: 00:00:14\u001b[2K\u001b[G  35.1% [=========>                  ] 35.11/100.00 ela: 00:00:07 rem: 00:00:14\u001b[2K\u001b[G  35.5% [==========>                 ] 35.48/100.00 ela: 00:00:08 rem: 00:00:14\u001b[2K\u001b[G  36.0% [==========>                 ] 35.96/100.00 ela: 00:00:08 rem: 00:00:14\u001b[2K\u001b[G  36.4% [==========>                 ] 36.45/100.00 ela: 00:00:08 rem: 00:00:14\u001b[2K\u001b[G  37.0% [==========>                 ] 36.95/100.00 ela: 00:00:08 rem: 00:00:14\u001b[2K\u001b[G  37.4% [==========>                 ] 37.39/100.00 ela: 00:00:08 rem: 00:00:14\u001b[2K\u001b[G  37.9% [==========>                 ] 37.89/100.00 ela: 00:00:08 rem: 00:00:14\u001b[2K\u001b[G  38.4% [==========>                 ] 38.37/100.00 ela: 00:00:08 rem: 00:00:13\u001b[2K\u001b[G  38.6% [==========>                 ] 38.60/100.00 ela: 00:00:08 rem: 00:00:13\u001b[2K\u001b[G  39.1% [===========>                ] 39.06/100.00 ela: 00:00:08 rem: 00:00:13\u001b[2K\u001b[G  39.4% [===========>                ] 39.43/100.00 ela: 00:00:08 rem: 00:00:13\u001b[2K\u001b[G  39.8% [===========>                ] 39.79/100.00 ela: 00:00:09 rem: 00:00:13\u001b[2K\u001b[G  40.0% [===========>                ] 39.96/100.00 ela: 00:00:09 rem: 00:00:13\u001b[2K\u001b[G  40.1% [===========>                ] 40.13/100.00 ela: 00:00:09 rem: 00:00:13\u001b[2K\u001b[G  40.5% [===========>                ] 40.54/100.00 ela: 00:00:09 rem: 00:00:13\u001b[2K\u001b[G  40.8% [===========>                ] 40.83/100.00 ela: 00:00:09 rem: 00:00:13\u001b[2K\u001b[G  41.3% [===========>                ] 41.26/100.00 ela: 00:00:09 rem: 00:00:13\u001b[2K\u001b[G  41.7% [===========>                ] 41.70/100.00 ela: 00:00:09 rem: 00:00:13\u001b[2K\u001b[G  42.1% [===========>                ] 42.12/100.00 ela: 00:00:09 rem: 00:00:13\u001b[2K\u001b[G  42.5% [===========>                ] 42.51/100.00 ela: 00:00:09 rem: 00:00:13\u001b[2K\u001b[G  42.8% [============>               ] 42.79/100.00 ela: 00:00:09 rem: 00:00:13\u001b[2K\u001b[G  43.3% [============>               ] 43.26/100.00 ela: 00:00:10 rem: 00:00:13\u001b[2K\u001b[G  43.6% [============>               ] 43.62/100.00 ela: 00:00:10 rem: 00:00:13\u001b[2K\u001b[G  44.1% [============>               ] 44.08/100.00 ela: 00:00:10 rem: 00:00:13\u001b[2K\u001b[G  44.5% [============>               ] 44.54/100.00 ela: 00:00:10 rem: 00:00:12\u001b[2K\u001b[G  44.9% [============>               ] 44.88/100.00 ela: 00:00:10 rem: 00:00:12\u001b[2K\u001b[G  45.3% [============>               ] 45.26/100.00 ela: 00:00:10 rem: 00:00:12\u001b[2K\u001b[G  45.6% [============>               ] 45.55/100.00 ela: 00:00:10 rem: 00:00:12\u001b[2K\u001b[G  45.9% [============>               ] 45.88/100.00 ela: 00:00:10 rem: 00:00:12\u001b[2K\u001b[G  46.4% [=============>              ] 46.35/100.00 ela: 00:00:10 rem: 00:00:12\u001b[2K\u001b[G  46.8% [=============>              ] 46.83/100.00 ela: 00:00:10 rem: 00:00:12\u001b[2K\u001b[G  47.3% [=============>              ] 47.28/100.00 ela: 00:00:11 rem: 00:00:12\u001b[2K\u001b[G  47.6% [=============>              ] 47.65/100.00 ela: 00:00:11 rem: 00:00:12\u001b[2K\u001b[G  48.0% [=============>              ] 47.99/100.00 ela: 00:00:11 rem: 00:00:12\u001b[2K\u001b[G  48.3% [=============>              ] 48.27/100.00 ela: 00:00:11 rem: 00:00:12\u001b[2K\u001b[G  48.5% [=============>              ] 48.46/100.00 ela: 00:00:11 rem: 00:00:12\u001b[2K\u001b[G  48.8% [=============>              ] 48.76/100.00 ela: 00:00:11 rem: 00:00:12\u001b[2K\u001b[G  49.1% [=============>              ] 49.08/100.00 ela: 00:00:11 rem: 00:00:12\u001b[2K\u001b[G  49.3% [=============>              ] 49.34/100.00 ela: 00:00:11 rem: 00:00:12\u001b[2K\u001b[G  49.5% [=============>              ] 49.50/100.00 ela: 00:00:11 rem: 00:00:12\u001b[2K\u001b[G  49.8% [=============>              ] 49.81/100.00 ela: 00:00:11 rem: 00:00:12\u001b[2K\u001b[G  50.1% [==============>             ] 50.08/100.00 ela: 00:00:12 rem: 00:00:12\u001b[2K\u001b[G  50.4% [==============>             ] 50.41/100.00 ela: 00:00:12 rem: 00:00:11\u001b[2K\u001b[G  50.8% [==============>             ] 50.76/100.00 ela: 00:00:12 rem: 00:00:11\u001b[2K\u001b[G  51.1% [==============>             ] 51.06/100.00 ela: 00:00:12 rem: 00:00:11\u001b[2K\u001b[G  51.5% [==============>             ] 51.50/100.00 ela: 00:00:12 rem: 00:00:11\u001b[2K\u001b[G  51.9% [==============>             ] 51.92/100.00 ela: 00:00:12 rem: 00:00:11\u001b[2K\u001b[G  52.2% [==============>             ] 52.23/100.00 ela: 00:00:12 rem: 00:00:11\u001b[2K\u001b[G  52.6% [==============>             ] 52.61/100.00 ela: 00:00:12 rem: 00:00:11\u001b[2K\u001b[G  52.9% [==============>             ] 52.91/100.00 ela: 00:00:12 rem: 00:00:11\u001b[2K\u001b[G  53.3% [==============>             ] 53.30/100.00 ela: 00:00:12 rem: 00:00:11\u001b[2K\u001b[G  53.7% [==============>             ] 53.67/100.00 ela: 00:00:13 rem: 00:00:11\u001b[2K\u001b[G  54.1% [===============>            ] 54.10/100.00 ela: 00:00:13 rem: 00:00:11\u001b[2K\u001b[G  54.4% [===============>            ] 54.43/100.00 ela: 00:00:13 rem: 00:00:11\u001b[2K\u001b[G  54.9% [===============>            ] 54.85/100.00 ela: 00:00:13 rem: 00:00:11\u001b[2K\u001b[G  55.2% [===============>            ] 55.19/100.00 ela: 00:00:13 rem: 00:00:10\u001b[2K\u001b[G  55.6% [===============>            ] 55.58/100.00 ela: 00:00:13 rem: 00:00:10\u001b[2K\u001b[G  56.0% [===============>            ] 55.97/100.00 ela: 00:00:13 rem: 00:00:10\u001b[2K\u001b[G  56.4% [===============>            ] 56.38/100.00 ela: 00:00:13 rem: 00:00:10\u001b[2K\u001b[G  56.8% [===============>            ] 56.79/100.00 ela: 00:00:13 rem: 00:00:10\u001b[2K\u001b[G  57.2% [===============>            ] 57.16/100.00 ela: 00:00:14 rem: 00:00:10\u001b[2K\u001b[G  57.5% [================>           ] 57.53/100.00 ela: 00:00:14 rem: 00:00:10\u001b[2K\u001b[G  58.0% [================>           ] 57.95/100.00 ela: 00:00:14 rem: 00:00:10\u001b[2K\u001b[G  58.4% [================>           ] 58.35/100.00 ela: 00:00:14 rem: 00:00:10\u001b[2K\u001b[G  58.6% [================>           ] 58.64/100.00 ela: 00:00:14 rem: 00:00:10\u001b[2K\u001b[G  58.9% [================>           ] 58.87/100.00 ela: 00:00:14 rem: 00:00:10\u001b[2K\u001b[G  59.3% [================>           ] 59.27/100.00 ela: 00:00:14 rem: 00:00:10\u001b[2K\u001b[G  59.7% [================>           ] 59.66/100.00 ela: 00:00:14 rem: 00:00:09\u001b[2K\u001b[G  60.0% [================>           ] 60.00/100.00 ela: 00:00:14 rem: 00:00:09\u001b[2K\u001b[G  60.3% [================>           ] 60.34/100.00 ela: 00:00:14 rem: 00:00:09\u001b[2K\u001b[G  60.6% [================>           ] 60.58/100.00 ela: 00:00:15 rem: 00:00:09\u001b[2K\u001b[G  61.0% [================>           ] 60.99/100.00 ela: 00:00:15 rem: 00:00:09\u001b[2K\u001b[G  61.3% [=================>          ] 61.31/100.00 ela: 00:00:15 rem: 00:00:09\u001b[2K\u001b[G  61.7% [=================>          ] 61.72/100.00 ela: 00:00:15 rem: 00:00:09\u001b[2K\u001b[G  62.1% [=================>          ] 62.09/100.00 ela: 00:00:15 rem: 00:00:09\u001b[2K\u001b[G  62.4% [=================>          ] 62.43/100.00 ela: 00:00:15 rem: 00:00:09\u001b[2K\u001b[G  62.9% [=================>          ] 62.92/100.00 ela: 00:00:15 rem: 00:00:09\u001b[2K\u001b[G  63.3% [=================>          ] 63.34/100.00 ela: 00:00:15 rem: 00:00:09\u001b[2K\u001b[G  63.8% [=================>          ] 63.78/100.00 ela: 00:00:15 rem: 00:00:08\u001b[2K\u001b[G  64.2% [=================>          ] 64.24/100.00 ela: 00:00:15 rem: 00:00:08\u001b[2K\u001b[G  64.7% [=================>          ] 64.66/100.00 ela: 00:00:16 rem: 00:00:08\u001b[2K\u001b[G  65.0% [==================>         ] 64.97/100.00 ela: 00:00:16 rem: 00:00:08\u001b[2K\u001b[G  65.4% [==================>         ] 65.42/100.00 ela: 00:00:16 rem: 00:00:08\u001b[2K\u001b[G  65.9% [==================>         ] 65.86/100.00 ela: 00:00:16 rem: 00:00:08\u001b[2K\u001b[G  66.1% [==================>         ] 66.12/100.00 ela: 00:00:16 rem: 00:00:08\u001b[2K\u001b[G  66.4% [==================>         ] 66.45/100.00 ela: 00:00:16 rem: 00:00:08\u001b[2K\u001b[G  66.7% [==================>         ] 66.68/100.00 ela: 00:00:16 rem: 00:00:08\u001b[2K\u001b[G  67.1% [==================>         ] 67.09/100.00 ela: 00:00:16 rem: 00:00:08\u001b[2K\u001b[G  67.5% [==================>         ] 67.50/100.00 ela: 00:00:16 rem: 00:00:08\u001b[2K\u001b[G  67.7% [==================>         ] 67.73/100.00 ela: 00:00:16 rem: 00:00:08\u001b[2K\u001b[G  68.1% [==================>         ] 68.06/100.00 ela: 00:00:17 rem: 00:00:07\u001b[2K\u001b[G  68.3% [==================>         ] 68.33/100.00 ela: 00:00:17 rem: 00:00:07\u001b[2K\u001b[G  68.7% [===================>        ] 68.68/100.00 ela: 00:00:17 rem: 00:00:07\u001b[2K\u001b[G  69.0% [===================>        ] 69.02/100.00 ela: 00:00:17 rem: 00:00:07\u001b[2K\u001b[G  69.4% [===================>        ] 69.39/100.00 ela: 00:00:17 rem: 00:00:07\u001b[2K\u001b[G  69.7% [===================>        ] 69.73/100.00 ela: 00:00:17 rem: 00:00:07\u001b[2K\u001b[G  70.1% [===================>        ] 70.06/100.00 ela: 00:00:17 rem: 00:00:07\u001b[2K\u001b[G  70.4% [===================>        ] 70.38/100.00 ela: 00:00:17 rem: 00:00:07\u001b[2K\u001b[G  70.7% [===================>        ] 70.68/100.00 ela: 00:00:17 rem: 00:00:07\u001b[2K\u001b[G  71.0% [===================>        ] 71.01/100.00 ela: 00:00:17 rem: 00:00:07\u001b[2K\u001b[G  71.3% [===================>        ] 71.32/100.00 ela: 00:00:18 rem: 00:00:07\u001b[2K\u001b[G  71.6% [===================>        ] 71.65/100.00 ela: 00:00:18 rem: 00:00:07\u001b[2K\u001b[G  72.0% [===================>        ] 71.96/100.00 ela: 00:00:18 rem: 00:00:07\u001b[2K\u001b[G  72.1% [===================>        ] 72.14/100.00 ela: 00:00:18 rem: 00:00:07\u001b[2K\u001b[G  72.4% [====================>       ] 72.39/100.00 ela: 00:00:18 rem: 00:00:07\u001b[2K\u001b[G  72.8% [====================>       ] 72.82/100.00 ela: 00:00:18 rem: 00:00:06\u001b[2K\u001b[G  73.2% [====================>       ] 73.23/100.00 ela: 00:00:18 rem: 00:00:06\u001b[2K\u001b[G  73.6% [====================>       ] 73.62/100.00 ela: 00:00:18 rem: 00:00:06\u001b[2K\u001b[G  74.0% [====================>       ] 74.04/100.00 ela: 00:00:18 rem: 00:00:06\u001b[2K\u001b[G  74.4% [====================>       ] 74.40/100.00 ela: 00:00:18 rem: 00:00:06\u001b[2K\u001b[G  74.7% [====================>       ] 74.74/100.00 ela: 00:00:19 rem: 00:00:06\u001b[2K\u001b[G  75.1% [====================>       ] 75.06/100.00 ela: 00:00:19 rem: 00:00:06\u001b[2K\u001b[G  75.4% [====================>       ] 75.44/100.00 ela: 00:00:19 rem: 00:00:06\u001b[2K\u001b[G  75.9% [====================>       ] 75.88/100.00 ela: 00:00:19 rem: 00:00:06"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K\u001b[G  76.2% [=====================>      ] 76.25/100.00 ela: 00:00:19 rem: 00:00:06\u001b[2K\u001b[G  76.6% [=====================>      ] 76.62/100.00 ela: 00:00:19 rem: 00:00:05\u001b[2K\u001b[G  77.0% [=====================>      ] 76.96/100.00 ela: 00:00:19 rem: 00:00:05\u001b[2K\u001b[G  77.3% [=====================>      ] 77.28/100.00 ela: 00:00:19 rem: 00:00:05\u001b[2K\u001b[G  77.6% [=====================>      ] 77.58/100.00 ela: 00:00:19 rem: 00:00:05\u001b[2K\u001b[G  77.9% [=====================>      ] 77.94/100.00 ela: 00:00:19 rem: 00:00:05\u001b[2K\u001b[G  78.3% [=====================>      ] 78.33/100.00 ela: 00:00:20 rem: 00:00:05\u001b[2K\u001b[G  78.6% [=====================>      ] 78.60/100.00 ela: 00:00:20 rem: 00:00:05\u001b[2K\u001b[G  78.9% [=====================>      ] 78.93/100.00 ela: 00:00:20 rem: 00:00:05\u001b[2K\u001b[G  79.2% [=====================>      ] 79.23/100.00 ela: 00:00:20 rem: 00:00:05\u001b[2K\u001b[G  79.6% [=====================>      ] 79.58/100.00 ela: 00:00:20 rem: 00:00:05\u001b[2K\u001b[G  79.9% [======================>     ] 79.94/100.00 ela: 00:00:20 rem: 00:00:05\u001b[2K\u001b[G  80.2% [======================>     ] 80.24/100.00 ela: 00:00:20 rem: 00:00:05\u001b[2K\u001b[G  80.5% [======================>     ] 80.54/100.00 ela: 00:00:20 rem: 00:00:05\u001b[2K\u001b[G  80.9% [======================>     ] 80.89/100.00 ela: 00:00:20 rem: 00:00:04\u001b[2K\u001b[G  81.2% [======================>     ] 81.22/100.00 ela: 00:00:20 rem: 00:00:04\u001b[2K\u001b[G  81.6% [======================>     ] 81.61/100.00 ela: 00:00:21 rem: 00:00:04\u001b[2K\u001b[G  82.0% [======================>     ] 82.00/100.00 ela: 00:00:21 rem: 00:00:04\u001b[2K\u001b[G  82.3% [======================>     ] 82.26/100.00 ela: 00:00:21 rem: 00:00:04\u001b[2K\u001b[G  82.6% [======================>     ] 82.57/100.00 ela: 00:00:21 rem: 00:00:04\u001b[2K\u001b[G  82.9% [======================>     ] 82.94/100.00 ela: 00:00:21 rem: 00:00:04\u001b[2K\u001b[G  83.3% [======================>     ] 83.30/100.00 ela: 00:00:21 rem: 00:00:04\u001b[2K\u001b[G  83.6% [=======================>    ] 83.65/100.00 ela: 00:00:21 rem: 00:00:04\u001b[2K\u001b[G  84.1% [=======================>    ] 84.08/100.00 ela: 00:00:21 rem: 00:00:04\u001b[2K\u001b[G  84.5% [=======================>    ] 84.50/100.00 ela: 00:00:21 rem: 00:00:04\u001b[2K\u001b[G  84.7% [=======================>    ] 84.72/100.00 ela: 00:00:21 rem: 00:00:03\u001b[2K\u001b[G  85.1% [=======================>    ] 85.09/100.00 ela: 00:00:22 rem: 00:00:03\u001b[2K\u001b[G  85.4% [=======================>    ] 85.44/100.00 ela: 00:00:22 rem: 00:00:03\u001b[2K\u001b[G  85.8% [=======================>    ] 85.82/100.00 ela: 00:00:22 rem: 00:00:03\u001b[2K\u001b[G  86.2% [=======================>    ] 86.21/100.00 ela: 00:00:22 rem: 00:00:03\u001b[2K\u001b[G  86.6% [=======================>    ] 86.61/100.00 ela: 00:00:22 rem: 00:00:03\u001b[2K\u001b[G  87.0% [=======================>    ] 86.99/100.00 ela: 00:00:22 rem: 00:00:03\u001b[2K\u001b[G  87.4% [========================>   ] 87.39/100.00 ela: 00:00:22 rem: 00:00:03\u001b[2K\u001b[G  87.7% [========================>   ] 87.75/100.00 ela: 00:00:22 rem: 00:00:03\u001b[2K\u001b[G  88.1% [========================>   ] 88.09/100.00 ela: 00:00:22 rem: 00:00:03\u001b[2K\u001b[G  88.5% [========================>   ] 88.52/100.00 ela: 00:00:23 rem: 00:00:02\u001b[2K\u001b[G  88.9% [========================>   ] 88.86/100.00 ela: 00:00:23 rem: 00:00:02\u001b[2K\u001b[G  89.2% [========================>   ] 89.18/100.00 ela: 00:00:23 rem: 00:00:02\u001b[2K\u001b[G  89.5% [========================>   ] 89.53/100.00 ela: 00:00:23 rem: 00:00:02\u001b[2K\u001b[G  89.8% [========================>   ] 89.79/100.00 ela: 00:00:23 rem: 00:00:02\u001b[2K\u001b[G  90.0% [========================>   ] 90.04/100.00 ela: 00:00:23 rem: 00:00:02\u001b[2K\u001b[G  90.4% [========================>   ] 90.39/100.00 ela: 00:00:23 rem: 00:00:02\u001b[2K\u001b[G  90.8% [=========================>  ] 90.79/100.00 ela: 00:00:23 rem: 00:00:02\u001b[2K\u001b[G  91.1% [=========================>  ] 91.11/100.00 ela: 00:00:23 rem: 00:00:02\u001b[2K\u001b[G  91.5% [=========================>  ] 91.47/100.00 ela: 00:00:23 rem: 00:00:02\u001b[2K\u001b[G  91.7% [=========================>  ] 91.69/100.00 ela: 00:00:24 rem: 00:00:02\u001b[2K\u001b[G  92.0% [=========================>  ] 92.02/100.00 ela: 00:00:24 rem: 00:00:02\u001b[2K\u001b[G  92.4% [=========================>  ] 92.37/100.00 ela: 00:00:24 rem: 00:00:01\u001b[2K\u001b[G  92.7% [=========================>  ] 92.69/100.00 ela: 00:00:24 rem: 00:00:01\u001b[2K\u001b[G  93.0% [=========================>  ] 93.03/100.00 ela: 00:00:24 rem: 00:00:01\u001b[2K\u001b[G  93.4% [=========================>  ] 93.42/100.00 ela: 00:00:24 rem: 00:00:01\u001b[2K\u001b[G  93.7% [=========================>  ] 93.73/100.00 ela: 00:00:24 rem: 00:00:01\u001b[2K\u001b[G  94.1% [=========================>  ] 94.05/100.00 ela: 00:00:24 rem: 00:00:01\u001b[2K\u001b[G  94.4% [=========================>  ] 94.39/100.00 ela: 00:00:24 rem: 00:00:01\u001b[2K\u001b[G  94.8% [==========================> ] 94.78/100.00 ela: 00:00:24 rem: 00:00:01\u001b[2K\u001b[G  95.1% [==========================> ] 95.14/100.00 ela: 00:00:25 rem: 00:00:01\u001b[2K\u001b[G  95.5% [==========================> ] 95.52/100.00 ela: 00:00:25 rem: 00:00:01\u001b[2K\u001b[G  95.9% [==========================> ] 95.90/100.00 ela: 00:00:25 rem: 00:00:01\u001b[2K\u001b[G  96.2% [==========================> ] 96.20/100.00 ela: 00:00:25 rem: 00:00:00\u001b[2K\u001b[G  96.5% [==========================> ] 96.52/100.00 ela: 00:00:25 rem: 00:00:00\u001b[2K\u001b[G  96.9% [==========================> ] 96.89/100.00 ela: 00:00:25 rem: 00:00:00\u001b[2K\u001b[G  97.3% [==========================> ] 97.26/100.00 ela: 00:00:25 rem: 00:00:00\u001b[2K\u001b[G  97.6% [==========================> ] 97.57/100.00 ela: 00:00:25 rem: 00:00:00\u001b[2K\u001b[G  97.9% [==========================> ] 97.86/100.00 ela: 00:00:25 rem: 00:00:00\u001b[2K\u001b[G  98.2% [===========================>] 98.23/100.00 ela: 00:00:25 rem: 00:00:00\u001b[2K\u001b[G  98.5% [===========================>] 98.49/100.00 ela: 00:00:26 rem: 00:00:00\u001b[2K\u001b[G  98.8% [===========================>] 98.84/100.00 ela: 00:00:26 rem: 00:00:00\u001b[2K\u001b[G  99.2% [===========================>] 99.19/100.00 ela: 00:00:26 rem: 00:00:00\u001b[2K\u001b[G  99.3% [===========================>] 99.33/100.00 ela: 00:00:26 rem: 00:00:00\u001b[2K\u001b[G  99.6% [===========================>] 99.65/100.00 ela: 00:00:26 rem: 00:00:00\u001b[2K\u001b[G 100.0% [===========================>] 100.00/100.00 ela: 00:00:26 rem: 00:00:00\n"
     ]
    }
   ],
   "source": [
    "!mpirun -np 4 pyfr run -b openmp -p ../code/pyfr/euler_vortex_2d.pyfrm ../code/pyfr/euler_vortex_2d.ini"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PyFR outputs in VTK format, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipyparallel as ipp\n",
    "c = ipp.Client()\n",
    "view = c[:]\n",
    "view.activate()\n",
    "view.run('/opt/conda/envs/pyfr/bin run -b openmp -p ../code/pyfr/euler_vortex_2d.pyfrm ../code/pyfr/euler_vortex_2d.ini')\n",
    "view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AsyncResult: execute>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "view = c[:]\n",
    "view.activate()\n",
    "view.run('/opt/conda/envs/pyfr/bin/pyfr')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cython\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Numba\n",
    "\n",
    "Numba provides code compilation like Cython, but does so in a simple, easy-to-use fashion.  All that's needed is to add a decorator (similar to a C/C++ pragma or Fortran directive) to compute kernel\n",
    "\n",
    "```python\n",
    "from numba import jit\n",
    "\n",
    "@jit\n",
    "def func(x):\n",
    "    # some loop or comutationally intensive kernel\n",
    "    return x\n",
    "```\n",
    "\n",
    "Python code with the `@jit` decorator are compiled at runtime (just-in-time) using the LLVM compiler, producing code that is on par with C/C++ and Fortran."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's what it look like:\n",
    "<img src=\"../img/numba_process.png\" style=\"height:450px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python at Pawsey\n",
    "\n",
    "Pawsey has a number of solutions for Python users:\n",
    "\n",
    "- Compiled Python modules (Versions 2&3)\n",
    "- Tuned NumPy/SciPy libraries (linked agains MKL and Cray-LibSci)\n",
    "- Job-Packing Methods\n",
    "- Shifter/Singularity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Job-Packing\n",
    "\n",
    "Users of Magnus and Galaxy are allocated an entire node, and charged accordingly, whether they use it all or not.  Many users want to run as many single-core Python jobs on a node as possible.  The easiest way to do that is to use job-packing in your SLURM jobscript."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```console\n",
    "#!/bin/bash -l\n",
    "#SBATCH --nodes=1\n",
    "#SBATCH --ntasks=24\n",
    "#SBATCH --ntasks-per-node=24\n",
    "#SBATCH --cpus-per-task=1\n",
    "#SBATCH --time=00:10:00\n",
    "#SBATCH --partition=debugq\n",
    "#SBATCH --account=pawsey0001\n",
    "#SBATCH --export=NONE\n",
    "\n",
    "module swap PrgEnv-crady PrgEnv-gnu\n",
    "module load python\n",
    "module load numpy\n",
    "module load scipy\n",
    "module load matplotlib\n",
    "\n",
    "srun --export=ALL -n 24 -N 1 python_job_wrapper.sh\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We run a single wrapper script across 24 cores.  The key is how we write our wrapper script:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "#!/bin/bash\n",
    "\n",
    "python voxelSlice.py qs-curie-${SLURM_PROCID}\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each instance of the wrapper script will call the Python interpreter, but we use the environment variable `SLURM_PROCID` to differentiate between the cores, and each core takes a different input data set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The benefit with this method is it usually require no changes to existing Python scripts, but may require some thought be given as to how to structure data inputs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Containers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pawsey also has Docker images available to use, particularly for Python users.  We have a program called Shifter installed on our Cray systems.  It allows for Docker containers to be run on a shared HPC system, while still maintaining performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../img/Shifter_OSU_allgather.png\" style=\"height:450px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../img/Shifter_OSU_bandwidth_reduced.png\" style=\"height:450px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Job scripts require minimal modification:\n",
    "    \n",
    "```\n",
    "#!/bin/bash\n",
    "#SBATCH --nodes=1\n",
    "#SBATCH --time=00:10:00\n",
    "#SBATCH --image=docker:pawsey/hpc-python:latest\n",
    " \n",
    " \n",
    "module load shifter\n",
    " \n",
    " \n",
    "srun -n 24 shifter python my_python_app.py <args>\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the Docker images provide a base of what most users would need to build their own images:\n",
    "    \n",
    "```\n",
    "FROM ubuntu:latest\n",
    "\n",
    "LABEL maintainer=\"brian.skjerven@pawsey.org.au\"\n",
    "\n",
    "RUN apt-get update \\\n",
    "      && apt-get install -y \\\n",
    "      cython \\\n",
    "      python-minimal \\\n",
    "      python-pip\n",
    "\n",
    "RUN pip install --upgrade pip \\\n",
    "      && pip install \\\n",
    "      astropy \\\n",
    "      h5py \\\n",
    "      matplotlib \\\n",
    "      nose \\\n",
    "      numpy \\\n",
    "      pytest \\\n",
    "      scipy \\\n",
    "      setuptools\n",
    "\n",
    "CMD [\"/bin/bash\"]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The other benefit to using Python in a container is related to dynamic library loading:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../img/shifter_magnus.png\" style=\"height:450px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Thoughts\n",
    "\n",
    "- Make use of Pawsey compiled Python libraries (performance and module compatibility)\n",
    "- Try to use MPI capable libraries\n",
    "- Multiprocess *can* be useful, but there is a performance hit\n",
    "- Other Python options available to users (Shifter, job-packing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pyfr]",
   "language": "python",
   "name": "conda-env-pyfr-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
